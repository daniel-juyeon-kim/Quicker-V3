## Quicker V3

[Quicker V2](https://github.com/daniel-juyeon-kim/Quicker-V2)를 NestJS로 마이그레이션 한 프로젝트로 Nest IoC 컨테이너를 통한 의존성 주입 관리, Transactional 데코레이터 구현, 쿼리튜닝을 했습니다.

### 3차 부하 테스트: 커넥션 풀 최적화로 TPS 40% 증가 [더보기](<docs/2025.08/3차 부하 테스트: 서버 인스턴스 커넥션 풀 조정으로 제한된 환경에서 TPS 40프로 증가.md>)

> ##### 2025.08.28 ~ 2025.08.30 (2일)

#### [문제]

2차 부하테스트에서 EC2 서버 인스턴스를 스케일 아웃한 후, `RDS db.t4g.micro`의 **CPU 사용률 70~80%, 커넥션 수가 한계(60개)에 근접하면서 타임아웃이 발생**했습니다.

#### [해결]

RDS 인스턴스 스케일 업과 서버의 커넥션 풀을 조절하는 방법 중 추가 비용이 발생하지 않는 커넥션 풀 최적화를 선택했습니다.

EC2 t2.micro 서버 인스턴스에 적합한 커넥션 풀 크기는 기본 커넥션 풀(10)보다 작을 것으로 가정하고 아래와 같이 [커넥션을 5 → 3 → 2로 줄이며 검증](<docs/2025.08/3차 부하 테스트: 서버 인스턴스 커넥션 풀 조정으로 제한된 환경에서 TPS 40프로 증가.md#검증>)했습니다.

- 커넥션 5개: CPU 사용률 90%, 최대 240TPS, 응답 시간 0.5s
- 커넥션 3개: CPU 사용률 90%, 최대 220TPS, 응답 시간 0.8s
- 커넥션 2개: CPU 사용률 90%, 최대 210TPS, 응답 시간 1s

커넥션 수를 2~3개로 줄이면 RDS 부하는 완화되지만 응답 시간이 0.8 ~ 1s로 증가해 클라이언트 관점에서 문제가 된다고 생각했습니다. 반면 5개로 설정했을 때는 RDS 부하를 줄이면서도 응답 시간을 0.5s로 유지할 수 있어 적절하다고 판단했습니다.

이에 따라 EC2 t2.micro **서버 인스턴스를 6 → 8로 증설, 커넥션 풀 크기를 10 → 5로 축소**해 아래와 같은 성과가 있었습니다.

- **타임아웃 방지**
- **최대 TPS 1,000 → 1,400까지 향상 (40% 증가)**

### 2차 부하 테스트: 로드밸런서로 EC2 CPU 병목 해결 [더보기](<docs/2025.08/2차 부하 테스트: 로드밸런서로 병렬 EC2 인스턴스를 구성해 CPU 사용률 20프로 축소, TPS 4배 증가.md>)

> ##### 2025.08.28 ~ 2025.08.28 (1일)

#### [문제]

1차 부하 테스트 이후 가상 사용자를 1,000명까지 늘리면서 **EC2 서버 인스턴스의 CPU 사용률이 80%에 도달하며 병목**이 발생했습니다.

#### [해결]

추가 비용이 발생하는 스케일 업 대신, AWS 프리 티어를 최대한 활용할 수 있는 스케일 아웃으로 **t2.micro 인스턴스를 1 → 6대로 늘리고 로드밸런서로 부하를 분산**시켜 아래와 같은 성과가 있었습니다.

- **각 EC2 인스턴스 CPU 사용률: 80% → 40~60%**
- **최대 TPS: 245 → 1,000 (약 4배 향상)**

### 1차 부하 테스트: 인덱스로 RDS CPU 병목 해결 [더보기](<docs/2025.08/1차 부하 테스트: 인덱스로 RDS CPU 사용률 60프로 감소, 최대 TPS 9배 증가.md>)

> ##### 2025.08.27 ~ 2025.08.28 (1일)

#### [문제]

"배송원이 배송 가능한 의뢰 조회"는 배송원이 의뢰인의 의뢰를 수락하기 위해 반드시 사용하는 서비스의 핵심 기능으로 **가장 요청이 많아 응답시간과 TPS가 중요**합니다. 해당 기능에 부하 테스트를 진행한 결과, **RDS CPU 사용률 80%, 최대 25TPS**를 기록하며 병목이 발생했습니다.

#### [해결]

이전에 RDS와 연동한 테스트 코드의 응답시간이 100ms 미만으로 짧아 RDS CPU의 부하가 적을 것으로 예상했으나 부하 테스트 결과에서 CPU 사용률이 80%에 달했습니다.

원인은 조회 조건인 `user.walletAddress`에 인덱스가 없어 Full Table Scan이 발생했고 이를 해결하기 위해 해당 컬럼에 Unique 인덱스를 추가해 아래와 같은 성능 향상이 있었습니다.

- **RDS CPU 사용률: 80% → 20%**
- **최대 TPS: 25 → 245 (9배 증가)**

이 과정에서 **응답시간으로 CPU 사용률을 판단할 수 없다**는 것을 알게 되었습니다.

### 2차 쿼리튜닝: 페이지네이션 [더보기](<docs/페이지네이션 적용.md>)

#### [문제]

1차 쿼리 튜닝으로 레이턴시를 단축했지만, 로깅 및 외부API를 함께 수행하기에 37257ms는 여전히 길어 **100ms 이하로 추가 개선이 필요했습니다.**

#### [해결]

아래 방법의 장단점을 비교한 결과, 페이지네이션이 가장 적합하다고 판단했습니다.

역정규화

- 장점: **join최소화** 가능
- 단점: `order` 테이블 구조 변경으로 관련 코드 전면 수정 → **일의 규모가 너무 큼**

멀티 컬럼 인덱스

- 단점: 조건절이 `and`, `is null`, `!=` 연산이 있어 장점 없음

페이지네이션

- 장점: **I/O가 적어** 빠르고 `plainToInstance`의 **객체 변환 시간 단축** 가능
- 단점: **API 요청 증가**

[limit, offset으로 조회 건수를 10만 → 20으로 줄이고](<docs/페이지네이션 적용.md#1차-코드>) [서브쿼리로 통신 횟수를 줄여](<docs/페이지네이션 적용.md#2차-코드>), 레이턴시를 **37257ms → 74ms로 단축**했습니다.

### 1차 쿼리튜닝: 불필요한 join 제거 [더보기](<docs/불필요한 join 제거.md>)

#### [문제]

아래의 환경과 연동한 레포지토리 메서드는 레이턴시가 **333437ms로 길었습니다.**

- AWS RDS db.t4g.micro (MySQL Community)
- 100만 order 레코드(10%는 매칭 X)
- 2만 user 레코드(1인당 평균 의뢰 50개)

#### [해결]

로그와 `EXPLAIN ANALYZE`를 통해 [의도치 않게 발생한 join을 확인하고](<docs/불필요한 join 제거.md#해결>), [수정해](<docs/불필요한 join 제거.md#코드-1>) 레이턴시를 **333437ms → 37257ms로 88.8% 단축**했습니다.

### Transactional 데코레이터를 구현하여 AOP적용 [더보기](<docs/TypeORM 트랜잭션 데코레이터 만들기.md>)

#### [문제]

TypeORM 0.3 부터 `Transaction` 데코레이터가 삭제되서 `EntityManager.transaction`으로 트랜잭션을 했습니다. 다음과 같은 문제가 있었습니다.

- 레포지토리에 `TransactionalEntityManager`를 전달하면서 **인터페이스가 커짐**
- 서비스 계층 메서드 내부에서 트랜잭션 코드를 작성해 **비즈니스 로직에 집중이 떨어짐**

#### [해결]

**트랜잭션 코드를 Transactional 데코레이터로 추출해 AOP를 적용**했습니다. NestJS CLS로 요청마다 [독립된 컨텍스트에 `EntityManager`를 두고 핼퍼로 접근](<docs/TypeORM 트랜잭션 데코레이터 만들기.md#동작-흐름>)해 DB 작업을 합니다. 다음과 같은 이점이 있습니다.

- 레포지토리 **인터페이스 축소**
- 서비스 계층에서 비즈니스 로직에 더 집중할 수 있음

#### 사용 기술

**Back:** TypeScript, NestJS, TypeORM, Mongoose, SlackAPI, Naver SMS API
**DB:** MariaDB, MongoDB
**Compute:** AWS RDS
**Tool:** Git, Slack, Swagger, Jest
