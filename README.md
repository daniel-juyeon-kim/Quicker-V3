## Quicker V3

> Quicker는 블록체인을 통한 수수료 공개로 이용자에게 비용 전가, 수수료 담합 등의 문제를 해결한 퀵 배송 중개 서비스입니다.

**Quicker V3**는 [Quicker V2](https://github.com/daniel-juyeon-kim/Quicker-V2)(Express)를 NestJS로 마이그레이션한 프로젝트로 아래와 같은 문제를 해결했습니다.

- **병목 개선:** **5번의 부하 테스트**에서 인덱스 추가, 서버 스케일 아웃, 커넥션 풀 조정, 역정규화 등을 통해 **최대 TPS를 25 → 4,400까지 증가**
- **응답 시간 개선:** **2번의 쿼리 튜닝**(JOIN 제거, 페이지네이션 + 서브쿼리)으로 **응답 시간을 333s → 74ms로 단축**
- **코드 품질 향상(AOP):** 트랜잭션과 비즈니스 로직이 섞인 문제를 **`@Transactional` 데코레이터로 분리**해 해결
- **의존성 주입 관리:** 객체 생성과 주입 관리를 Nest IoC 컨테이너로 해결

### 5차 부하 테스트: 별도로 필터링된 테이블, 로직 변경으로 TPS 3,000 → 4,400 46% 향상 [더보기](<docs/2025.09/5차 부하 테스트: 필터링된 테이블 및 비즈니스 로직 조정으로 TPS 46프로 향상.md>)

> ##### 2025.09.28 ~ 29, 2025.10.03 ~ 04 (4일)

#### [문제]

4차 부하 테스트에서 역정규화로 최대 3,000 TPS 까지 향상시켰으나, `RDS db.t4g.micro`의 **CPU 사용률은 95%**로 병목이 존재했습니다. 부하 테스트 환경은 아래와 같습니다.

- AWS RDS t4g.micro (MySQL Community) × 1
  - `order` 1,000만 건(조회 대상: 10%)
  - `user` 20만 건(1인 평균 `order` 50건)
- AWS EC2 t2.micro (Ubuntu) × 8

#### [해결]

**RDS 복제, 캐싱 도입은 비용 증가, 추가 관리의 문제가 있어** RDS 내부에서 해결하기 위해 **쿼리 튜닝에 집중**했습니다. **필터링된 데이터를 별도 테이블에서 관리, 비즈니스 로직을 변경해 최대 3,000 → 4,400 TPS로 약 46% 향상**시켰습니다.

1. **[필터링된 테이블](<docs/2025.09/5차 부하 테스트: 필터링된 테이블 및 비즈니스 로직 조정으로 TPS 46프로 향상.md#1단계-필터링-전용-테이블-도입>):** 배송 가능한 의뢰만 별도 테이블을 추가해, 필터링 제거와 탐색 범위 축소로 **3,000 → 3,300 TPS, 10% 향상**
2. **[비즈니스 로직 변경](<docs/2025.09/5차 부하 테스트: 필터링된 테이블 및 비즈니스 로직 조정으로 TPS 46프로 향상.md#2단계-비즈니스-로직-변경을-통한-조회-조건-최소화>):** 비즈니스 로직을 수정으로 인덱스 활용이 불가한 `!=` 조건을 제거해 풀 스캔 방지하여 **3,300 → 4,400 TPS, 33% 추가 향상**

### 4차 부하 테스트: 역정규화로 RDS CPU 부하 감소, TPS 1,400 → 3,000 2배 증가 [더보기](<docs/2025.08/4차 부하 테스트: 역정규화로 RDS 병목을 해결, 최대 TPS 2배 향상.md>)

> ##### 2025.09.12 ~ 2025.09.15 (4일)

#### [문제]

3차 부하 테스트에서 커넥션 풀을 최적화했으나, 여전히 **RDS의 CPU 사용률은 80~90**%로 개선이 필요했습니다. 부하 테스트 환경은 아래와 같습니다.

- AWS RDS t4g.micro (MySQL Community) × 1
  - `order` 1,000만 건(조회 대상: 10%)
  - `user` 20만 건(1인 평균 `order` 50건)
- AWS EC2 t2.micro (Ubuntu) × 8
  - 커넥션 풀: 5

#### [해결]

**응답 시간이 낮고 RDS CPU 사용률이 높은** 현상은 [1차 부하 테스트에서 인덱스가 없었을 때 발생한 상황](<docs/2025.08/1차 부하 테스트: 인덱스로 RDS CPU 사용률 60프로 감소, 최대 TPS 9배 증가.md>)과 유사했고 짐작되는 원인 중 **과도한 `JOIN`** 발생이 있어 역정규화 하는 방법을 고려했습니다.

빠른 해결이 필요하지 않은 상황이고 재발 가능성을 줄이기 위해 아래의 방법 중, **역정규화로 `JOIN` 연산을 줄여 최대 TPS를 1,400 → 3,000으로 2배 증가**시켰습니다.

- **DB 캐싱**
  - 장점: **확실한 RDS의 부하 감소**
  - 단점: **추가적인 인프라 관리** 필요 + 서버에 추가 작업 필요, 재발 가능성 존재(과도한 `JOIN`연산)
- **역정규화**
  - 장점: **과도한 `JOIN`연산 없음**, RDS의 부하 감소
  - 단점: **데이터 이관 작업 필수(작업 비용↑)**
- **복제**
  - 장점: **가장 간단하고 빠르며 확실한 RDS의 부하 감소**
  - 단점: **추가 비용 발생**, **추가적인 인프라 관리** 필요, 재발 가능성 존재(과도한 `JOIN`연산)

### 3차 부하 테스트: 커넥션 풀 최적화로 TPS 1,000 → 1,400 40% 증가 [더보기](<docs/2025.08/3차 부하 테스트: 서버 인스턴스 커넥션 풀 조정으로 제한된 환경에서 TPS 40프로 증가.md>)

> ##### 2025.08.28 ~ 2025.08.30 (2일)

#### [문제]

2차 부하 테스트에서 EC2 서버를 6대로 늘린 후, `RDS db.t4g.micro`의 **CPU 사용률은 70~80%, 커넥션 수는 한계(60개)에 도달해 타임아웃이 발생**했습니다. 부하 테스트 환경은 아래와 같습니다.

- AWS RDS t4g.micro (MySQL Community) × 1
  - `order` 1,000만 건(조회 대상: 10%)
  - `user` 20만 건(1인 평균 `order` 50건)
- AWS EC2 t2.micro (Ubuntu) × 6
  - 커넥션 풀: 10 (기본값)

#### [해결]

**선택:** RDS 스케일 업, 서버의 커넥션 풀 축소 중, 서버의 기존 **커넥션 풀 크기 10은 `EC2 t2.micro`에 부적합**하다고 판단했습니다. **검증을 통해 적정 커넥션 크기를 찾고, 축소**하는 방법을 선택했습니다.

**가설/검증:** `EC2 t2.micro`에 **적합한 커넥션 풀 크기는 기본값인 10보다 작을 것으로 가정**하고 [5 → 3 → 2로 줄이며 검증](<docs/2025.08/3차 부하 테스트: 서버 인스턴스 커넥션 풀 조정으로 제한된 환경에서 TPS 40프로 증가.md#가설/검증>)했습니다. 결과는 **CPU 사용률 90%에 응답시간은 늘었습니다.**

- **커넥션 풀 크기 5개:** 최대 240TPS, **응답시간 0.5s**
- **커넥션 풀 크기 3개:** 최대 220TPS, **응답시간 0.8s**
- **커넥션 풀 크기 2개:** 최대 210TPS, **응답시간 1s**

**성과:** **응답 시간이 0.8s 이상이라면 클라이언트 관점에서 문제**가 된다고 판단해서 **커넥션 풀 크기를 10 → 5로 축소, 서버 인스턴스를 6 → 8로 증설**해 **타임아웃을 방지**하고 **최대 TPS를 1,000 → 1,400으로 40% 증가**시켰습니다.

### 2차 부하 테스트: 로드밸런서로 EC2 CPU 병목 해결, TPS 245 → 1,000 4배 증가 [더보기](<docs/2025.08/2차 부하 테스트: 로드밸런서로 병렬 EC2 인스턴스를 구성해 CPU 사용률 20프로 감소, TPS 4배 증가.md>)

> ##### 2025.08.28 ~ 2025.08.28 (1일)

#### [문제]

1차 부하 테스트 이후 가상 사용자를 1,000까지 늘리면서 **EC2 서버 인스턴스의 CPU 사용률이 80%에 도달해 병목**이 발생했습니다. 부하 테스트 환경은 아래와 같습니다.

- AWS RDS t4g.micro (MySQL Community) × 1
  - `order` 1,000만 건(조회 대상: 10%)
  - `user` 20만 건(1인 평균 `order` 50건)
- AWS EC2 t2.micro (Ubuntu) × 1

#### [해결]

서버 스케일 업/아웃 중 추가 비용 발생이 없는 **t2.micro 서버를 1 → 6대로 늘리고 AWS ALB로 부하를 분산**시켜 해결했습니다.

- 각 EC2 CPU 사용률: **80 → 40~60%**
- 최대 TPS: **245 → 1,000 약 4배 증가**

### 1차 부하 테스트: 인덱스로 RDS CPU 병목 해결, TPS 25 → 245 9배 증가 [더보기](<docs/2025.08/1차 부하 테스트: 인덱스로 RDS CPU 사용률 60프로 감소, 최대 TPS 9배 증가.md>)

> ##### 2025.08.27 ~ 2025.08.28 (1일)

#### [문제]

`배송원이 배송 가능한 의뢰 조회`는 서비스의 핵심 기능으로 **가장 요청이 많아, 응답시간과 TPS가 중요**한데, **부하 테스트 결과는 RDS CPU 사용률 80%, 최대 25 TPS**로 개선이 필요했습니다. 부하 테스트환경은 아래와 같습니다.

- AWS RDS t4g.micro (MySQL Community) × 1
  - `order` 1,000만 건(조회 대상: 10%)
  - `user` 20만 건(1인 평균 `order` 50건)
- AWS EC2 t2.micro (Ubuntu) × 1

#### [해결]

쿼리의 실행 계획을 분석한 결과, **인덱스 부재**로 인해 `user.walletAddress`에서 [**Full Table Scan이 발생**](<docs/2025.08/1차 부하 테스트: 인덱스로 RDS CPU 사용률 60프로 감소, 최대 TPS 9배 증가.md#explain-analyze-실행-계획-인덱스-추가-전>)했습니다. 해당 컬럼에 **UNIQUE 인덱스를 추가**해 아래와 같은 성능 향상이 있었습니다.

- RDS CPU 사용률: **80 → 20%**
- 최대 TPS: **25 → 245 (약 9배 증가)**

단일 요청 테스트에서 **응답시간이 100ms 미만이라 RDS CPU의 부하가 적을 것으로 예상**했으나 이 과정에서 **인덱스는 조회 속도만 개선하는 것이 아니라 불필요한 I/O를 줄여 CPU 사용률을 낮출 수 있다는 것**을 알게 되었습니다.

### 2차 쿼리튜닝: 페이지네이션 [더보기](<docs/페이지네이션 적용.md>)

> ##### 2025.08.02 ~ 2025.08.04 (3일)

#### [문제]

1차 쿼리 튜닝에서 응답시간을 37s까지 단축했지만, 로깅, 외부 API 호출, 전송 시간을 고려할 때 **100ms 이하로 단축이 필요했습니다.** 테스트 환경은 아래와 같습니다.

- AWS RDS t4g.micro (MySQL Community) × 1
  - `order` 100만 → 1,000만 건(조회 대상: 10%)
  - `user` 2만 → 20만 건(1인 평균 `order` 50건)

#### [해결]

아래의 방법 중 **작업 효율이 좋은 페이지네이션을 선택**했습니다.

- **역정규화**
  - 장점: **JOIN 최소화** 가능
  - 단점: `order` 테이블 역정규화로 **데이터 이관 작업, 연관된 코드 전면 수정 필수** → **작업비용이 큼**
- **멀티 컬럼 인덱스**
  - 장점: 작업 비용이 낮음
  - 단점: 조회 조건이 `and`, `is null`, `!=` 연산이라 작업 효율이 낮음
- **페이지네이션**
  - 장점: 가장 간단함, **I/O가 적어** 빠르고 `plainToInstance`의 **객체 변환 시간 단축**
  - 단점: **API 요청 증가**

[`limit`, `offset`으로 조회 데이터를 10만 → 20건으로 줄이고](<docs/페이지네이션 적용.md#1차-코드>) [서브쿼리로 통신 횟수를 줄여](<docs/페이지네이션 적용.md#2차-코드>), 응답시간을 **37257 → 74ms로 단축**했습니다.

### 1차 쿼리튜닝: 불필요한 join 제거 [더보기](<docs/불필요한 join 제거.md>)

> ##### 2025.07.30 ~ 2025.08.02 (1주)

#### [문제]

아래의 환경과 연동한 `배송원이 배송 가능한 의뢰 조회` 테스트 코드는 응답시간이 **333s로 길었습니다.** 테스트 환경은 아래와 같습니다.

AWS RDS t4g.micro (MySQL Community) × 1

- `order` 100만 건(조회 대상: 10%)
- `user` 2만 건(1인 평균 `order` 50건)

#### [해결]

로그와 실행 계획을 통해 [의도치 않게 발생한 JOIN을 확인했고](<docs/불필요한 join 제거.md#해결>), [수정해](<docs/불필요한 join 제거.md#코드-1>) 응답시간을 **333 → 37s로 88.8% 단축**했습니다.

### Transactional 데코레이터를 구현하여 AOP 적용 [더보기](<docs/TypeORM 트랜잭션 데코레이터 만들기.md>)

> ##### 2025.02.20 ~ 2025.02.26 (1주)

#### [문제]

TypeORM 0.3 부터 `Transaction` 데코레이터가 삭제되었고 `EntityManager.transaction`으로 트랜잭션을 수행했는데 아래와 같은 문제가 있었습니다.

- `TransactionalEntityManager` 전달로 **레포지토리 계층의 인터페이스가 커짐**
- 서비스 계층 메서드에서 트랜잭션 코드 작성으로 **비즈니스 로직 집중도 하락**

#### [해결]

**트랜잭션 코드를 Transactional 데코레이터로 추출해 AOP를 적용**했습니다. 매 요청마다 [독립된 NestJS CLS 컨텍스트에 `EntityManager`를 두고 핼퍼로 접근](<docs/TypeORM 트랜잭션 데코레이터 만들기.md#동작-흐름>)해 DB 작업을 하면서 아래와 같은 이점이 있었습니다.

- 레포지토리 계층 **인터페이스 축소**
- 서비스 계층에서 **비즈니스 로직의 집중도 향상**

### 사용 기술

**Back:** TypeScript, NestJS\
**DB:** TypeORM, Mongoose, MySQL, MongoDB\
**Test:** Jest, K6\
**Cloud:** AWS (EC2, RDS, ALB)\
**Etc:** Git, Swagger, OpenAI API, Slack API, Naver SMS API